## 教务体系建设

**主题：** 履约域

**总线矩阵**

业务过程：用户购买正价课-到课-参课-完课-课程转化-复购/退课退款

维度：学员\课程\商品\班级\助教

**数仓建设**

ODS：15张后端数据快照表

DIM：小节、课程、商品、教育用户多身份表(助教表)、学员信息表

DWD 

| table            | 业务过程                                                     | 声明粒度                      | 确认维度                                                   | 确认事实                                     |
| :--------------- | ------------------------------------------------------------ | ----------------------------- | ---------------------------------------------------------- | -------------------------------------------- |
| 一次学习记录宽表 | 学员参课完课的一次记录。课堂的时间、持续时长和相关资源的使用情况 | 小节ID+学员ID                 | 学员维度；课程维度；时间维度；资源维度(教室资源，平台环境) | 学习时长；进出时间；课程状态                 |
| 学员学习进度宽表 | 学员到课参课完课的周期和进度。                               | 一次学习记录的ID(resource_id) | 学员维度；课程维度；时间维度；资源维度                     | 学习持续时间；进度和完成情况；参与度；       |
| 售后-换课表      | 学员的退课换课情况                                           | 事件ID                        | 学员维度；课程维度；商品维度                               | 事件类型；新旧商品的度量；退款金额；处理人工 |
| 触达逻辑表       | 助教和学员接触后学员的买课退课换课情况                       | 助教ID+学员ID                 | 助教维度；学员维度；课程维度；渠道维度                     | 相关课程ID；聊天渠道；                       |

DWS：

| table                | 聚集维度                                                     | 统计周期           | 聚集事实                                              |
| -------------------- | ------------------------------------------------------------ | ------------------ | ----------------------------------------------------- |
| 直播间粒度学习汇总表 | 每个 `resource_id` 表示一个独立的直播间，直播间是分析的主要实体 | 直播时间           | 到课/完课人数；转化用户数，转化用户金额；平均观看时长 |
| 线索订单直播间转化表 | 订单维度 + 直播内容维度（section）+ 用户维度                 | 下单日期           | 小节时长；是否直播转化；实际金额；是否转化；          |
| 课程粒度学习汇总表   | course_id                                                    | 开课日期到当前日期 | 到课/完课率 ；平均学习时长；退课/换课人数             |

ADS：助教服务表\期数到课完课表\直播间在线人数

**数仓建设问题和难点：**

1. 触达未建设，期数到课完课，助教服务表都需要触达数据，四张ods表关联。业务需求变更，增加了指标以及指标的计算方式。ADS直接调用osd数据。  而且触达逻辑复杂：助教ods表，用户账户ods表，企业微信聊天记录表。

   解决方案：建设 触达逻辑表
2. 逻辑、指标重复建设

   **例子：** 一次进出直播间学习数据宽表和一次进出视频课的学习数据表=>一次学习记录宽表。
3. 数仓建设混乱。

   **例子：** 建设学员信息表在dwd层。存储学员的信息和课程学习记录。建设学员学习进度宽表。在dim层建设学员信息表。
4. 指标定义不一致：

   周数的定义：业务方认为小节距离第一节课的开课时间有多少周，也就是每个小节的周数不一样；数仓的定义是结束时间-开课时间，整个课开了多少周

**数据本身的问题：**

1. 测试数据和真实数据未分离，且未标识。例如，存在很多课程命名为0的数据，对计算汇总数据影响
2. 业务变更导致主键不唯一，但是业务方未知。例如，crm的线索clue_id对应一个订单id（业务方认为）。实际探查中，一个clue_id对应多个order_id，且clue_id本应唯一，存在重复数据。
3. 数据字段混乱，不一致。需要反复确认

**质量控制：**

1. 数据源探查，数据主键(业务变更主键不唯一)、数据量(数据量与数据建设完成后的数据量一致)，key值的唯一性（防止笛卡尔积或者数据量对不上），null或者0检测，type类型检测，
2. 数据表建设完成后数据自测：1、主键唯一性； 2、数据量对比；3、null值检测，type类型及数据量检测
3. DQC监控：唯一性监控、掉0监控或者其他数据量波动检测、null值监控、特殊值监控（比如完课时间>开课时间）

**数据治理：**

1. 数据量不一致问题：可能一些限制条件不一致，例如：有些去掉null，有些去掉测试数据

**模型建设的思路：**

1、高内聚低耦合
将业务相近、粒度相同的数据设计为一个物理模型
将高频同时访问的数据设计在一起，把低频同时访问的数据分开存储

2、核心模型与拓展模型分离
建立核心模型和拓展模型体系，核心模型包括核心字段，常用字段；拓展模型包括个性化字段。降低维护成本

3、公共层逻辑下沉且主题单一
底层公用的处理逻辑在dwd层封装实现

4、成本与性能平衡

5、数据可回滚：不修改代码逻辑，重跑回滚结果不变

6、数据一致性
字段命名一致性
指标定义的口径一致性

6、命名清晰，符合命名系统要求

## 教育全链路

**业务路径：** 社区投放广告曝光->点击广告,分配线索(取生成意向的线索)->销售加微信，生成意向->引流课下单学习->购买正价课/退费-复购的业务过程进行串连。

* **生成线索** ：用户点击引流课广告并查看课程详情时，系统自动记录为线索。
* **跟进线索** ：销售团队联系线索，介绍课程细节，鼓励用户参加引流课。
* **生成意向** ：用户购买引流课程后，系统将此行为转化为购买正价课的意向。

**粒度：** 意向ID

**作用：** 

- 全链路漏斗：计算各种引流课下单率、正价转化率、到课率
- 线索归因：销售归因，意向归因最近的线索
- 异常数据监控：用户数、重复率、空值率、销售冲突率

**数据问题：** 

- 多个意向对应一个线索，取最后一次意向对应的线索，保证唯一。

* 数据重复：同时销售也有可能是助教，但是销售，助教单独建设了两个表，数据重复

**操作产生的新问题：** 两个表合并，增加身份的字段，一个人的数据变成了两行（不同的身份），但是没有做好数据探查。下游数据2倍增长，指标的计算产生了误差

![大宽表流程.jpg](https://github.com/JinboYao/Education-all-link-wide-table-construction/blob/main/%E5%A4%A7%E5%AE%BD%E8%A1%A8%E6%B5%81%E7%A8%8B.jpg?raw=true)

## 数据治理项目

**1、问题**

- 数据存储：随着业务线的增多，数据存储的压力也越来越大，公司提出降本增效的数据治理专项，减少存储压力
- 数据质量：1、主键不唯一，数据波动 2、数据链路运行时间过长
- 数据应用：缺乏统一的基础数据指标和应用分析标准：具体表现在各个业务线（业务含义一致，命名不一致；业务含义不一致，命名含义一致）。各个系统存在冗余（埋点组做了投放卡片转化的数据，教育线单独再做一套投放转化数据）。
- 业务代码定义混乱：早期个性化需求不符合当前的业务（线索不唯一），上层业务基于早期的数据表搭建，存在数据问题。业务开发的结果不符合业务方预期

**2、治理方案：**

- 数据资产管理： 
  - 梳理数据资产，对90天没有使用下游的数据进行下线操作
  - 梳理表的生命周期，根据级别进行生命周期调整
- 数据质量：
  - 完整性：
    - 建立完整性约束：主键唯一性监控、NULL值监控、
    - 数据量完整性：掉0风险；全量数据每天数据量不会减少，
  - 准确性：
    - 重要指标根据来源做数据对账
    - 层级数据量监控：汇总的数据就做数据量对比。
  - 一致性：
    - 数据一致性：1、指标口径标准化，元数据管理。追溯指标的来源表，字段和逻辑；2、多层指标一致性校验；3、根据SQL逻辑构建字段级血缘图，做变更预警+审批
    - 维度一致性：1、建立统一维度中心管理 2、明确维度，做维度口径字典表
  - 及时性：
    - 整理90天内运行时间超过1小时的数据表，整理成excel表
    - 数据优化，减少运行时长。运行时长超过30min的Spark任务，运行时长超过2h的HIVE任务优化
- 数据标准管理：统一命名系统。设置词根库，保证表名称、结构 、字段命名一致
- 数据安全治理：1.数据定级加密   2.敏感数据(电话、身份证等) 加密
- 主数据管理：联合业务进行业务梳理，重新进行数据构建。梳理数仓结构，审核总线矩阵和数据建设
- 元数据管理：采集表结构信息，解析SQL提取血缘；构建数据地图，实现字段追溯

**3、成果：**

数据治理项目历时3个月，下线临时表与无效表46张，优化数据表30张，获得了2022技术中台降本增效「项目奖 - 大数据成本治理」奖项

## 智能中医药数据分析系统

**1、Apriori（关联）**

目的：找到关联药物组合，方便分析疾病的核心药物组

算法：

**计算频繁项集**

​	支持度：一个项集在所有业务中出现的频次

- 计算支持度->单项频繁项集->合并->计算多项频繁相集，中途剪枝->生成关联规则

​	置信度：A->B 在所有包含A的事物中也包含B的概念，在发生a的情况下，b也发生的概率

- 强关联规则。**置信度**(**A**→**B**)**=**支持度**(**A**∪**B**)/**支持度**(**A**)**

**2、ALBERT-BILSTM-CRF（命名实体识别）**

- ALBERT:  ALBERT用于学习和提取输入文本的深层语义特征，从而为下游任务（如命名实体识别）提供强大的上下文依赖的文本表示。

- BiLSTM:  在ALBERT提取的特征上进一步建模，BiLSTM可以细化这些特征，捕捉序列数据中的时间依赖性，为实体边界的精确预测提供支持。

- CRF：  CRF层接收BiLSTM的输出，并输出最可能的标签序列，考虑到标签之间的约束关系，以形成一致和合法的实体识别


**3、CNN算法（舌诊）**

- 自动特征提取
- 对每张图片进行详细的标注，包括舌头的颜色、形状、舌苔厚度和颜色

**4、复杂熵聚类算法(聚类)**

目的：找出处方组合规律和潜在分组模式

计算步骤：

- 构建**向量模型**(`词袋模型`)，把处方向量化构建0/1矩阵(药物是否出现在处方集中）

- 计算每个处方的熵(衡量处方的复杂度)

  ```
  熵反映了“信息分布更均匀、更分散”的程度。处方的药物越多，熵数量越大
  ```

- 计算处方间的相似度/距离

  - **Jaccard 相似度**（药物成分相似度）

    处方`共同的药有多少`/ `所有的药物`

  - **熵差**（结构复杂度差异）

    熵差越小越相似

  混合距离函数：

  ```
  熵差 + (1 - jaccard)  # 越小越相似
  ```

- 层次聚类

  根据混合距离数画二叉数聚类

**5、Noe4j 知识图谱**

三元组  [实体，关系，实体]

## 蚂蚁DANA项目

**事实/过程**：记录具有欺诈信号的交易、登录、注册等操作

**维度**：提供反欺诈所需的上下文，如用户、设备、IP、时间、位置、信任

**风险域**

| 表名                                          | 业务过程                                | 维度                                                         |
| --------------------------------------------- | --------------------------------------- | ------------------------------------------------------------ |
| dwd_evt_ctu_event_hi用户交易行为              | 用户交易的事件以及支付相关的信息        | 事件ID，用户ID和交易对象，地理位置，交易金额时间，地理位置设备信息 |
| dwd_user_login_detail用户登录行为             | 每次登录                                | IP，地理位置，设备                                           |
| dwd_device_change_detail 设备更换记录         | 设备更换记录                            |                                                              |
| dwd_evt_ctu_event_source_dd确认的欺诈案件数据 | 欺诈和被拒绝的事件记录                  | 事件ID，用户ID                                               |
| dwd_evt_ctu_result_hi命中风控规则明细         | 事件的决策分析结果，事件的拦截/通过情况 | 事件ID，决策，                                               |
| dwd_evt_ctu_analyze_result_detail_hi          | 记录哪个策略、模型，规则，触发规则      | 策略uuid，strategy_uuid                                      |

**DIM**

- 用户基本信息（实名、注册时间等）
- 设备信息（品牌、操作系统、是否为模拟器）
- 地理区域编码维表
- 风控策略维表（ID、名称、风险等级）

| DWS                            |                                              |      |      |
| ------------------------------ | -------------------------------------------- | ---- | ---- |
| dws_user_risk_feature_day      | 按日汇总每个用户的风险行为特征               |      |      |
| dws_device_risk_feature_day    | 每天设备行为聚合，识别“多账户设备”“黑产设备” |      |      |
| dws_user_risk_rule_summary_day | 每天统计用户命中的风控策略、计算风险得分     |      |      |

ADS层

| ADS设计                                                      | 描述                                                         | 重要指标 |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| adm_ctu_mod_dana_trust_list_dd<br />黑白名单用户总表         | 黑名单库，白名单库                                           |          |
| ads_user_rfm_metrics_dd<br /> RFM指标表                      | 历史⾸次使⽤⾄今时间间隔(R); 历史使⽤天数(F)；历史交易⾦额(M)；历史最近⼀次使⽤时间；<br />IP;卡索引；DANA设备指纹； |          |
| adm_ctu_mod_dana_trust_object_hotspot_lst_dd<br />热点数据表 | 识别热点用户、热点国家、热点IP、异常登录地点、设备等，辅助风控策略迭代和黑名单发现 |          |

![【4】全面了解风控数据体系 - 图1](https://geekdaxue.co/uploads/projects/yingtaoxiang@hello/64b298431136f50e287402caa54ff48b.png)

## 数据迁移任务

**背景：**

印尼DANA 计划将数据和任务从 DaaS CTU 迁移到阿⾥云（maxcompute）。金融云产品支持过时，出现问题修复和数据回填艰难

蚂蚁金融云（类似于阿里云）的架构：

* HDFS 数据存储
* DQS 任务开发
* JSS 任务调度和运行
* Hbase  推送数据到数仓，以增量的数据形式
* Oceanbase  存储全量数据
* DTM和DataX 做数据同步

**前置探查**

* 上游数据是否有依赖其他领域的数据
* 下游有依赖迁移数据的任务
* 检查迁移任务中有没有直接调用数据仓库的任务

**迁移步骤**

- **任务**
  - 表结构：将表结构复制到MaxCompute，调整字段类型，分区兼容；
  - 任务调度迁移到DataWorks

- **数据**
  - Dataworks 的数据集成把HDFS数据迁移到MaxCompute
  - ODPS Spark和DataX把数据同步到ODS层

- **脚本**
  - 配置数据验证脚本和监控


**完成后测试与监控**

- 双轨并行策略：迁移阶段新老系统同步跑，每天比对数据一致性
- 自动化校验链路：每张表迁移后自动生成校验结果和差异表

```sql
SELECT
    (SELECT COUNT(*) FROM OldTable) AS OldTableCount,
    (SELECT COUNT(*) FROM NewTable) AS NewTableCount,
    (CASE 
        WHEN (SELECT COUNT(*) FROM (
            SELECT * FROM OldTable
            EXCEPT
            SELECT * FROM NewTable
        ) t) = 0 AND (SELECT COUNT(*) FROM (
            SELECT * FROM NewTable
            EXCEPT
            SELECT * FROM OldTable
        ) t) = 0 THEN 'Data match'
        ELSE 'Data do not match'
    END) AS DataComparisonResult;
```



![](https://intranetproxy.alipay.com/skylark/lark/0/2024/png/144956724/1721197807834-43fdbf8c-7ec6-45cd-b8ea-79f0eb9c8d88.png)![1725516996056](image/项目/1725516996056.png)

## [大数据量场景](https://juejin.cn/post/7222787944296267831)

**分治、Hash、BitMap、布隆过滤器、堆排序**

### 1.两个大文件里找到重复URL

问题：A文件有 50亿条 url(url为字符串)，B文件也有 50亿条 url，每条 ur大小为 64B,在一台只有 4G内存的机器上计算，怎么找出A,B中相同的 url?

1G=1024M B=1024 * 1024 KB  = 1024* 1024 * 1024 B ~= 10^9 B

50亿 URL= 50 * 10^8 * 64 B =32 * 10^10 B = 320G

解答：

首先遍历文件 a，对遍历到的 URL 通过哈希取模的方式：hash（URL）%100，根据计算结果把 URL 放入 a0，a1 ... a99.txt 这 100 个文件中，每个文件大小约为 3.2 GB。用同样的方法遍历文件 b，将 URL 拆分到 b0, b1 ... b99.txt 文件中。

拆分过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0，...，a99 对应 b99。接下来只需求出这 100 对小文件中相同的 URL 就好了。

求相同的 URL，可以用 HashSet/HashMap 的方式，当 URL 存在 Set/Map 中时，说明 URL 重复，就可以把重复的 URL 保存在单独的文件中，最终合并所有相同的 URL 即可。

### 2.海量个数字中，找出不重复的整数

问题：在 100 亿个整数中找出不重复的数字，注意：内存不足以容纳这么多个整数。

100 x 10^8 x 4B 约为 40GB

1. HashMap+分治

   100亿个整数分配到1000个文件，每个文件存储1000万个整数，编号0-999，遍历存入HashMap。

   再计算只出现一次的整数
2. 位图法

   我们用 2 个 bit 来表示数字出现的状态：00 表示没出现过、01 表示出现过一次、10 表示出现了多次。100 亿整数都是 int 类型，每个整数占 4 个字节，即 32 个 bit，需要的内存为 2^32 x 2bit = 1GB。

   当可用内存大于 1GB 时，可用位图法解决本题。通过遍历这 100 亿个数，将对应下标 00->01（整数出现 1 次），01->10（整数出现多次），最后统计 01（只出现了一次）的个数即可。

### 3.海量电话号码中，统计不同号码的个数

**位图法**

由于电话号码长度为 11 位，每一位上的数字有 10 种情况，因此需申请长度为 1 千亿（10^11）的 bit 数组，大约需要内存 10^11 x 1bit 约为 12.5GB。遍历所有的号码，当出现该号码时将该数组位置为 1，用一个数 count 记录第一次置为 1 的位图元素，遍历结束后得出最终结果。

## 数据质量架构

**数据治理体系**

![图片](https://i-blog.csdnimg.cn/blog_migrate/575dd3b1e574e4633bae7c12aeeedfb1.png)

1. 数据质量

   - 完整性

     - 建立完整性约束：如主键约束、外键约束等
     - 数据监控和告警：监控数据缺失或者数据值缺失

   - 准确性

     - 数据对账
     - 数据整合

   - **一致性**

     `建统一维度表 + 维度口径手册` 和`构建指标库 + 报表对账脚本 + 血缘分析`

     - 数据一致性：1、指标口径标准化，元数据管理。追溯指标的来源表，字段和逻辑；2、多层指标一致性校验；3、根据SQL逻辑构建字段级血缘图，做变更预警+审批
     - 维度一致性：1、建立统一维度中心管理 2、明确维度，做维度口径字典表

   - 及时性

     - 超时告警

   ![图片](https://i-blog.csdnimg.cn/blog_migrate/2d578419f59bcaf87db39f5051cab01e.png)

2. 主数据管理

   企业业务系统间数据的管理。方便理解，检查搭建的完善度。

3. 元数据管理

   采集表结构信息，解析SQL提取血缘

   构建数据地图，实现字段追溯

4. 数据资产

   ![图片](https://i-blog.csdnimg.cn/blog_migrate/d8a21c36b3b2bdd249380e274e7541e3.png)

5. 数据标准

   统一的数据标准平台：`词根库，命名规范，码值库，字典管理`

6. 数据安全

   ![图片](https://i-blog.csdnimg.cn/blog_migrate/903f86577a82824ae9e0520fc66c77e8.png)



## DANA客户域项目

用户手机号注册、实名认证(手机号、银行卡、证件号码)

**DWD**

| 表名             | 表内容                                                       |
| ---------------- | ------------------------------------------------------------ |
| 用户注册信息表   | 用户基本信息、注册设备信息(渠道、终端、设备信息、IP)、认证信息 |
| 用户登录日志事实 | 登录时间、IP、设备                                           |
| 用户状态变更     | 注销、冻结、解冻                                             |
| 用户信息变更明显 | 基本信息变更记录表                                           |

**DIM**

- 日期维表
- 地区维表
- 终端维表
- 渠道维表
